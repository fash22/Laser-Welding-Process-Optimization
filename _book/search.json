[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Optimizing Laser Welded Steel-copper Lap Joints",
    "section": "",
    "text": "Photo by Sergio Rota on Unsplash\n\n\n\nPreface\nWelcome to this article on laser welding and welding cracks. In this comprehensive guide, we will delve into the fascinating world of laser welding, exploring its applications, advantages, and the challenges associated with welding cracks. Laser welding is a cutting-edge process that has revolutionized various industries, enabling precise and efficient joining of materials. However, welding cracks can pose significant risks to the quality and cost-effectiveness of the welding process. Therefore, our objective in this study is to identify the optimal parameters and factors that can minimize welding cracks, ultimately improving product quality and reducing associated costs. By following the CRISP-DM methodology and analyzing the “Screening datasets for laser welded steel-copper lap joints” dataset, we will uncover valuable insights into the relationship between welding process parameters and welding cracks. Join us on this journey as we explore the intricacies of laser welding and discover effective strategies to mitigate welding cracks."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Laser welding is a process that utilizes a high-powered laser beam to join materials together. It is commonly used in various industries such as automotive, aerospace, and electronics. The purpose of laser welding is to create strong and precise welds with minimal heat input, resulting in reduced distortion and improved overall quality. Compared to traditional welding processes, laser welding offers several advantages including higher welding speeds, smaller heat-affected zones, and the ability to weld dissimilar materials.\nWelding cracks are defects that can occur during the welding process. These cracks can significantly impact the quality and cost of the final product. They can compromise the structural integrity of the weld, leading to potential failures and safety hazards. Additionally, the presence of welding cracks often requires rework or scrap, increasing production costs and causing delays. Therefore, it is crucial to minimize welding cracks to ensure high-quality and cost-effective welding operations.\nThe aim of this project is to reduce the cost of rework and scrap, as well as minimize the risk of customer/market claims related to welding cracks. By identifying the optimal parameters and factors that can minimize welding cracks, businesses can improve their welding processes, enhance product quality, and reduce associated costs.\nThe objective of this study is to find the optimal parameters/factors that can minimize welding cracks in laser welding. It involves identifying the important features that affect welding cracks and understanding the effect of each parameter/factor of the laser welding process on the occurrence of welding cracks.\nIn this project, we will be utilizing the CRoss-Industry Standard Process for Data Mining (CRISP-DM) methodology. CRISP-DM is a widely recognized and proven approach for solving data mining problems. It consists of six phases: Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, and Deployment. By following this methodology, we can systematically analyze the data, develop models, and evaluate their effectiveness in addressing the problem statement.\nThe “Screening datasets for laser welded steel-copper lap joints” dataset will be used in this study. This dataset contains various parameters and factors related to laser welding, as well as information on the occurrence of welding cracks. By applying the CRISP-DM methodology to this dataset, we can gain insights into the relationship between the welding process parameters and welding cracks, and ultimately identify the optimal conditions for minimizing welding cracks."
  },
  {
    "objectID": "laser-welding-process.html",
    "href": "laser-welding-process.html",
    "title": "2  Laser Welding Process",
    "section": "",
    "text": "The laser welding process described in the dataset involves joining steel and copper lap joints using a high-powered laser beam. The steel-copper lap joints were prepared by overlapping a steel sheet and a copper sheet, creating a joint area where the laser welding would take place. The dataset includes six factors that were varied during the laser welding process.\nThese factors are:\n\nLaser beam power (W): This refers to the power of the laser beam used in the welding process. It determines the intensity of the laser beam and can affect the depth and quality of the weld.\nWelding speed (m/min): The welding speed refers to the rate at which the laser beam moves along the joint during the welding process. It affects the heat input and the cooling rate, which can influence the formation of welding cracks.\nAngular position in welding direction (°): This factor represents the angular position of the laser beam in relation to the welding direction. It can affect the distribution of heat and the formation of welding cracks.\nFocal position (mm): The focal position refers to the distance between the laser beam focus and the joint surface. It determines the spot size and the energy density of the laser beam, which can impact the weld quality and the occurrence of welding cracks.\nGas flow rate (l/min): The gas flow rate represents the rate at which shielding gas is supplied during the welding process. Shielding gas is used to protect the weld pool from atmospheric contamination. The gas flow rate can influence the cooling rate and the formation of welding cracks.\nMaterial thickness of the steel sheet (mm): This factor represents the thickness of the steel sheet used in the lap joint. The thickness can affect the heat input and the cooling rate, which can influence the formation of welding cracks.\n\nThese factors were chosen based on their potential influence on the occurrence of welding cracks. To create the dataset, 18 parameter combinations were selected, representing different combinations of the six factors. Each parameter combination was repeated five times, resulting in a total of 90 welding experiments. Additionally, each sheet was cut four times to generate a total of 360 cross sections.\nEach line in the dataset represents a cross section that was evaluated for the dimensions of the weld metal. The dataset provides information on the weld depth and the gesometrical dimensions of the weld metal in the laser welded steel-copper lap joints.\nThe Screening datasets for laser welded steel-copper lap joints(see Rinne (2021)) has two versions: V1 and V2. In V1, the dataset includes information on the occurrence of welding cracks, as well as the dimensions of the weld metal. In V2, additional information on the occurrence of partial penetration and the dimensions of the heat-affected zone is included. The V1.1 and V2.1 versions of the dataset were created to address some inconsistencies and errors found in the original versions (V1 and V2). Overall, the dataset provides valuable information on the relationship between the welding process parameters and the occurrence of welding cracks in laser welded steel-copper lap joints. By analyzing this dataset, researchers can gain insights into the optimal conditions for minimizing welding cracks and improving the quality of laser welding operations.\n\n\n\n\nRinne, Jonas. 2021. “Screening Datasets for Laser Welded Steel-Copper Lap Joints.” Mendeley Data. https://doi.org/10.17632/2s5m3crbkd.2."
  },
  {
    "objectID": "project_overview.html#objective",
    "href": "project_overview.html#objective",
    "title": "3  Project Overview",
    "section": "3.1 Objective",
    "text": "3.1 Objective\nThis project is focused on the creation of a machine learning model capable of predicting crack formation in laser-welded steel-copper lap joints. By analyzing various process parameters, the model aims to understand and highlight the correlation between these parameters and the incidence of defects. The ultimate goal is to enhance the welding process, improve joint quality and reliability, and reduce costs associated with rework and scrap in industries utilizing laser welding for steel-copper lap joints."
  },
  {
    "objectID": "project_overview.html#solution-usage",
    "href": "project_overview.html#solution-usage",
    "title": "3  Project Overview",
    "section": "3.2 Solution Usage",
    "text": "3.2 Solution Usage\nThe proposed solution, a predictive machine learning model, will serve as an integral tool in the laser welding industry. The model, once trained and validated, can be incorporated into the manufacturing workflow.\nPrior to welding, the model will ingest process parameters such as laser power, welding speed, and focus position. It will then predict the likelihood of crack formation in the welded joint under these conditions.\nIn case of a high-risk prediction, parameters can be iteratively adjusted and re-evaluated by the model until an acceptable risk level is reached. This facilitates real-time optimization of the welding process, thereby reducing defect occurrence and enhancing product quality.\nFurthermore, the model can aid strategic planning and decision-making by offering insights into how different parameters influence weld quality. This can steer research and development towards more efficient welding techniques and technologies.\nIn essence, this machine learning model is poised to be a valuable asset for operational optimization and strategic planning in industries employing laser welding of steel-copper lap joints."
  },
  {
    "objectID": "project_overview.html#current-solution",
    "href": "project_overview.html#current-solution",
    "title": "3  Project Overview",
    "section": "3.3 Current Solution",
    "text": "3.3 Current Solution\nThe prevention of cracks in laser-welded steel-copper lap joints currently involves understanding the mechanism of solidification cracking and implementing measures to control it (Rinne et al. (2021), Gao et al. (2022)).\nSolidification cracking in welds is a synergistic effect of ε phase liquation, inclusions, and composition segregation (Rinne et al. (2021), Gao et al. (2022)). The welding process can cause grain boundary liquation, reducing cohesion between grains and resistance to intergranular crack propagation (Rinne et al. (2021), Gao et al. (2022)). Composition segregation within grains can induce lattice distortion, reducing the material’s plastic deformation capacity and increasing crack susceptibility (Rinne et al. (2021), Gao et al. (2022)).\nAn oscillating laser has been proposed as an effective solution to inhibit solidification cracking (Rinne et al. (2021), Gao et al. (2022)). Laser oscillating welding promotes grain refinement, solute diffusion, and the formation of uniformly distributed ε-Cu precipitated phases in welds (Rinne et al. (2021), Gao et al. (2022)). This improves intergranular bonding, reduces solidification cracking susceptibility, and increases resistance to plastic deformation (Rinne et al. (2021), Gao et al. (2022)). The tensile strength of joints using laser oscillating welding is 251 MPa, a 35.7% increase compared to 185 MPa using standard laser welding (Rinne et al. (2021), Gao et al. (2022)). The strain of joints using laser oscillating welding is 3.69, a 96% increase compared to 1.88 using standard laser welding (Rinne et al. (2021), Gao et al. (2022)).\nWhile these solutions enhance joint quality and reliability, they require a deep understanding of the welding process and careful parameter control. This is where our machine learning model can add significant value by accurately predicting crack formation based on process parameters and guiding optimization efforts."
  },
  {
    "objectID": "project_overview.html#problem-framing",
    "href": "project_overview.html#problem-framing",
    "title": "3  Project Overview",
    "section": "3.4 Problem Framing",
    "text": "3.4 Problem Framing\nThe problem is structured as a supervised learning task. We have a labeled dataset from Mendeley Data, with known occurrences of cracks in laser-welded steel-copper lap joints (the target variable) for various process parameters (the features). The objective is to train a model on this data to predict the target variable for new, unseen data.\nThe model will undergo offline training, meaning we will use a static dataset for training, and the model will not learn continuously from new data. Once trained and validated, the model can be deployed to predict crack occurrences based on specified input parameters.\nHowever, it’s crucial to acknowledge that while the initial model training is offline, periodic retraining may be required to maintain high predictive performance as welding processes and techniques evolve. This retraining would also be conducted offline, using a new static dataset encompassing the most recent welding data."
  },
  {
    "objectID": "project_overview.html#performance-metric",
    "href": "project_overview.html#performance-metric",
    "title": "3  Project Overview",
    "section": "3.5 Performance Metric",
    "text": "3.5 Performance Metric\nThe model’s performance will be evaluated using the F1 Score, a metric that balances precision and recall. Precision quantifies the proportion of positive identifications that were correct, while recall quantifies the proportion of actual positives correctly identified.\nThe F1 Score is especially useful in scenarios where both false positives and false negatives are present. In this project’s context, a false positive implies a prediction of crack formation where none occurs, and a false negative implies a prediction of no crack formation where one does occur. Both scenarios could have significant implications in the laser welding industry, making it crucial to minimize both, which is what the F1 Score aims to achieve.\nBy employing the F1 Score as our performance metric, we strive to develop a model that not only accurately predicts crack formation but also minimizes both false positives and false negatives."
  },
  {
    "objectID": "project_overview.html#performance-metric-and-business-objectives",
    "href": "project_overview.html#performance-metric-and-business-objectives",
    "title": "3  Project Overview",
    "section": "3.6 Performance Metric and Business Objectives",
    "text": "3.6 Performance Metric and Business Objectives\nThe F1 Score aligns with the business objective of this project, which is to develop a machine learning model capable of accurately predicting crack occurrence in laser-welded steel-copper lap joints based on process parameters. Understanding the relationship between these parameters and crack formation will optimize the welding process, minimize defects, enhance joint quality and reliability, reduce rework and scrap costs, and ultimately improve the bottom line for industries relying on laser welding of steel-copper lap joints.\nThe F1 Score is a measure of model accuracy that balances precision (the proportion of positive identifications that were correct) and recall (the proportion of actual positives correctly identified). This balance ensures the model accurately predicts crack formation while minimizing both false positives (predicting a crack will form when it does not) and false negatives (predicting a crack will not form when it does). Both scenarios could have significant implications in the laser welding industry, making it crucial to minimize both.\nBy employing the F1 Score as our performance metric, we aim to create a model that not only accurately predicts crack formation but also minimizes both false positives and false negatives. This aligns well with our business objective."
  },
  {
    "objectID": "project_overview.html#minimum-performance",
    "href": "project_overview.html#minimum-performance",
    "title": "3  Project Overview",
    "section": "3.7 Minimum Performance",
    "text": "3.7 Minimum Performance\nThe minimum performance required to meet the business objectives would be contingent on the specific needs and constraints of the industries utilizing this model. Generally, a high F1 Score would be desirable, indicating accurate crack prediction while minimizing both false positives and false negatives.\nFor example, an F1 Score of at least 0.85 could serve as a reasonable benchmark. This implies that the model correctly identifies the presence or absence of cracks 85% of the time, maintaining a balance between precision and recall.\nHowever, this is merely a guideline, and actual minimum performance may vary. Factors such as the cost implications of false positives and negatives, the overall impact on production efficiency, and industry standards for quality and reliability would all influence the acceptable performance level.\nThe ultimate objective is to create a model that aids in optimizing the welding process and minimizing defects, thereby enhancing product quality and reducing costs. Therefore, the model’s performance should be sufficiently high to achieve these goals."
  },
  {
    "objectID": "project_overview.html#similar-problems",
    "href": "project_overview.html#similar-problems",
    "title": "3  Project Overview",
    "section": "3.8 Similar Problems",
    "text": "3.8 Similar Problems\nThere are several comparable problems in the field of manufacturing and materials science where machine learning models have been used to predict outcomes based on various parameters. Here are a few examples:\n\nPredicting Welding Distortion: Just like predicting cracks in laser-welded steel-copper lap joints, predicting welding distortion is another problem in the welding industry (Rinne et al. (2021), Gao et al. (2022)). Machine learning models can be trained on various welding parameters and the resulting distortion to predict future distortions based on these parameters (Rinne et al. (2021), Gao et al. (2022)).\nPredicting Material Properties: Machine learning models have been used to predict the properties of materials based on their composition and manufacturing processes (Rinne et al. (2021), Gao et al. (2022)). This is similar to predicting cracks in laser-welded steel-copper lap joints, where the outcome (crack formation) is predicted based on various process parameters (Rinne et al. (2021), Gao et al. (2022)).\nQuality Control in Manufacturing: Machine learning models are often used in quality control applications in various manufacturing industries (Rinne et al. (2021), Gao et al. (2022)). These models can predict the quality of a product based on various factors such as machine settings, environmental conditions, and material properties (Rinne et al. (2021), Gao et al. (2022)).\n\nIn all these cases, the experience and tools used for developing and training the machine learning models can be reused. The process of data preprocessing, feature selection, model training, validation, and testing are common across these problems. Tools and libraries such as Python’s scikit-learn or TensorFlow can be used to develop the machine learning models. Furthermore, techniques for handling imbalanced data, tuning model parameters, and evaluating model performance can also be applied to this problem."
  },
  {
    "objectID": "project_overview.html#human-expertise",
    "href": "project_overview.html#human-expertise",
    "title": "3  Project Overview",
    "section": "3.9 Human Expertise",
    "text": "3.9 Human Expertise\nhuman expertise is available in the field of laser welding and machine learning. Experts in laser welding can provide valuable insights into the welding process, the formation of cracks, and the various parameters that affect weld quality. They can also help in collecting and labeling data for training the machine learning model.\nMachine learning experts, on the other hand, can help in developing and training the model. They can provide guidance on data preprocessing, feature selection, model selection, and hyperparameter tuning. They can also help in evaluating the performance of the model and suggesting improvements.\nCollaboration between these two groups of experts can be highly beneficial for this project. Laser welding experts can provide domain knowledge to guide the development of the machine learning model, while machine learning experts can apply their technical expertise to build a robust and accurate model."
  },
  {
    "objectID": "project_overview.html#methodology",
    "href": "project_overview.html#methodology",
    "title": "3  Project Overview",
    "section": "3.10 Methodology",
    "text": "3.10 Methodology\nTo solve this problem, the following steps would be conducted:\n\nExploratory Data Analysis: This step involves visualizing and summarizing the data to understand its characteristics, distribution, and patterns. It also helps to identify any outliers, missing values, or anomalies in the data.\nData Cleaning & Feature Engineering: This step involves preparing the data for modeling by removing or imputing any missing values, outliers, or noise. It also involves creating new features or transforming existing ones to capture more information from the data and improve the model performance.\nModel Selection: This step involves choosing the most suitable machine learning algorithm for the problem, based on the data type, size, complexity, and desired outcome. Some common algorithms for welding crack detection are convolutional neural networks, support vector machines, and random forests.\nHyper-parameter Tuning: This step involves finding the optimal values for the parameters that control the behavior and performance of the chosen algorithm. This can be done using techniques such as grid search, random search, or Bayesian optimization.\nEnsembling: This step involves combining multiple models to create a more robust and accurate model. This can be done using techniques such as bagging, boosting, or stacking.\nPresentation: This step involves presenting the results and insights from the model to the stakeholders, using appropriate visualizations, metrics, and explanations. It also involves discussing the limitations, challenges, and future directions of the model.\n\n\n\n\n\nGao, Zhongmei, Yuye Yang, Lei Wang, Bin Zhou, and Fei Yan. 2022. “Formation Mechanism and Control of Solidification Cracking in Laser-Welded Joints of Steel/Copper Dissimilar Metals.” Metals 12 (7): 1147. https://doi.org/10.3390/met12071147.\n\n\nRinne, Jonas, Sarah Nothdurft, Jörg Hermsdorf, Stefan Kaierle, and Ludger Overmeyer. 2021. “Investigations on Laser Welding of Dissimilar Joints of Stainless Steel and Copper for Hot Crack Prevention.” Journal of Laser Applications 33: 042042. https://doi.org/10.2351/7.0000489."
  },
  {
    "objectID": "retrieving-data.html#downloading-the-dataset",
    "href": "retrieving-data.html#downloading-the-dataset",
    "title": "4  Retrieving the Dataset",
    "section": "4.1 Downloading the Dataset",
    "text": "4.1 Downloading the Dataset\nTo download the this dataset, the following python function was defined and used.\n\nimport os\nimport urllib.request\nimport zipfile\n\ndef download_file(url, filename):\n    # Check if file already exists in the directory\n    if os.path.exists(f\"datasets/{filename}\"):\n        # Print the directory tree relative to the datasets folder\n        for root, dirs, files in os.walk(\"datasets\"):\n            level = root.replace(\"datasets\", \"\").count(os.sep)\n            indent = \" \" * 4 * (level)\n            print(f\"{indent}{os.path.basename(root)}/\")\n            subindent = \" \" * 4 * (level + 1)\n            for f in files:\n                print(f\"{subindent}{f}\")\n    else:\n        # Download the file from the internet\n        urllib.request.urlretrieve(url, f\"datasets/{filename}\")\n        print(f\"File '{filename}' downloaded successfully.\")\n        \n        # Extract the zip file\n        with zipfile.ZipFile(f\"datasets/{filename}\", 'r') as zip_ref:\n            zip_ref.extractall(\"datasets\")\n        \n        # Print the directory tree relative to the datasets folder\n        for root, dirs, files in os.walk(\"datasets\"):\n            level = root.replace(\"datasets\", \"\").count(os.sep)\n            indent = \" \" * 4 * (level)\n            print(f\"{indent}{os.path.basename(root)}/\")\n            subindent = \" \" * 4 * (level + 1)\n            for f in files:\n                print(f\"{subindent}{f}\")\n\nurl = \"https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/2s5m3crbkd-2.zip\"\nfilename = \"laser-welding.zip\"\ndownload_file(url, filename)\n\ndatasets/\n    laser-welding.zip\n    V1.csv\n    Screening datasets for laser welded steel-copper lap joints/\n        V1 and V2/\n            Definitive screening steel-copper lap joints V1.xlsx\n            Definitive screening steel-copper lap joints V2.xlsx\n        V1.1 and V2.1/\n            Definitiv screening steel-copper lap joints V1.1.xlsx\n            Definitive screening steel-copper lap joints V2.1.xlsx\n\n\nExplanation:\n\nThe code imports the necessary modules: os for file and directory operations, urllib.request for downloading files from the internet, and zipfile for extracting zip files.\nThe function download_and_extract_file takes two parameters: url (the URL of the file to be downloaded) and filename (the name of the file to be saved in the local directory).\nIt checks if the file already exists in the datasets directory using the os.path.exists function. If it exists, it prints the directory tree relative to the datasets folder using the os.walk function.\nIf the file does not exist, it downloads the file from the internet using urllib.request.urlretrieve and saves it in the datasets directory.\nIt then extracts the zip file using the zipfile.ZipFile context manager and the extractall method, saving the extracted files in the datasets directory.\nFinally, it prints the directory tree relative to the datasets folder using the os.walk function.\n\nThis code allows for downloading and extracting files from the internet, while also checking if the file already exists in the local directory. It provides a convenient way to manage datasets and avoid unnecessary downloads.\n\n\n\n\nRinne, Jonas. 2021. “Screening Datasets for Laser Welded Steel-Copper Lap Joints.” Mendeley Data. https://doi.org/10.17632/2s5m3crbkd.2."
  },
  {
    "objectID": "exploring-data.html#dropping-unwanted-variables",
    "href": "exploring-data.html#dropping-unwanted-variables",
    "title": "5  Data Wrangling",
    "section": "5.1 Dropping Unwanted Variables",
    "text": "5.1 Dropping Unwanted Variables\nBefore wrangling the data, its important to have a deeper understanding of the purpose of each columns. Thus, having known which of these columns were features, targets, and unwanted, would be a great help later during the modelling phase.\n\n5.1.1 Identifying the Feature Variables\nAs highlighted in the Laser Welding Process page, the dataset contains 6 features representing the 6 different factors to be studied. These factors include laser beam power, welding speed, angular position in welding direction, focal position, gas flow rate, and material thickness of the steel sheet. Additionally, there are 2 features for identifying the weld number and cross section position.\n\n5.1.1.1 Factors to be Studied\n\nLaser beam power (W)\nWelding speed (m/min)\nAngular position in welding direction (°)\nFocal position (mm)\nGas flow rate (l/min)\nMaterial thickness of the steel sheet (mm)\n\n\n\n5.1.1.2 Experiment Identification\n\nweld number\ncross section positon in the weld (mm)\n\n\n\n\n5.1.2 Identifying the Target Variables\nThe dataset contains 4 continuous target variables and 1 binary target variable. For this study, we will be focusing on the binary target variable, which indicates the presence or absence of cracking in the weld metal. The remaining 4 continuous target variables will be dropped from our analysis.\n\n5.1.2.1 Binary Target Variable\n\ncracking in the weld metal\n\n\n\n5.1.2.2 Continuous Variables\n\nweld seam width steel (µm)\nweld seam width copper (µm)\nweld depth copper (µm)\ngap\n\nThe python code below categorizes each of the columns of the dataset, and drops the unnecessary columns.\n\nFEATURES = [\n    'power (W)',\n    'welding speed (m/min)',\n    'gas flow rate (l/min)',\n    'focal position (mm)',\n    'angular position (°)',\n    'material thickness (mm)',\n]\n\nEXPERIMENT_ID = [\n    'weld number',\n    'cross section positon in the weld (mm)',\n]\n\nTARGET = [\n    'cracking in the weld metal',\n]\n\nUNNECESSARY_COLS = [\n    'weld seam width steel (µm)',\n    'weld seam width copper (µm)',\n    'weld depth copper (µm)',\n    'gap'\n]\n\n# Drop unnecessary columns\ndataset.drop(UNNECESSARY_COLS,inplace=True,axis=1)\n\n# Check the new dataset\ndataset.head().T\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\npower (W)\n1050\n1050\n1050\n1050\n1050\n\n\nwelding speed (m/min)\n1.0\n1.0\n1.0\n1.0\n1.0\n\n\ngas flow rate (l/min)\n15\n15\n15\n15\n15\n\n\nfocal position (mm)\n0\n0\n0\n0\n0\n\n\nangular position (°)\n0\n0\n0\n0\n0\n\n\nmaterial thickness (mm)\n0.6\n0.6\n0.6\n0.6\n0.6\n\n\nweld number\n1\n1\n1\n1\n2\n\n\ncross section positon in the weld (mm)\n8\n16\n24\n32\n8\n\n\ncracking in the weld metal\nno\nno\nno\nno\nno"
  },
  {
    "objectID": "exploring-data.html#encoding-categorical-variables",
    "href": "exploring-data.html#encoding-categorical-variables",
    "title": "5  Data Wrangling",
    "section": "5.2 Encoding Categorical Variables",
    "text": "5.2 Encoding Categorical Variables\nBefore feeding the dataset into machine learning models, we need to encode the categorical variable “cracking in the weld metal” into a numeric format. This can be done by mapping “yes” to 1 and “no” to 0.\n\ndataset[\"cracking in the weld metal\"] = dataset[\"cracking in the weld metal\"].map(\n    {\n        \"no\" : 0,\n        \"yes\": 1\n    },\n)\n\ndataset.head().T\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\npower (W)\n1050.0\n1050.0\n1050.0\n1050.0\n1050.0\n\n\nwelding speed (m/min)\n1.0\n1.0\n1.0\n1.0\n1.0\n\n\ngas flow rate (l/min)\n15.0\n15.0\n15.0\n15.0\n15.0\n\n\nfocal position (mm)\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nangular position (°)\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nmaterial thickness (mm)\n0.6\n0.6\n0.6\n0.6\n0.6\n\n\nweld number\n1.0\n1.0\n1.0\n1.0\n2.0\n\n\ncross section positon in the weld (mm)\n8.0\n16.0\n24.0\n32.0\n8.0\n\n\ncracking in the weld metal\n0.0\n0.0\n0.0\n0.0\n0.0"
  },
  {
    "objectID": "exploring-data.html#quantifying-missing-data",
    "href": "exploring-data.html#quantifying-missing-data",
    "title": "5  Data Wrangling",
    "section": "5.3 Quantifying Missing Data",
    "text": "5.3 Quantifying Missing Data\nTo ensure that our machine learning models can be trained effectively, we need to address any missing data. Fortunately, this dataset does not contain any missing data.\n\ndataset.isna().sum()\n\npower (W)                                 0\nwelding speed (m/min)                     0\ngas flow rate (l/min)                     0\nfocal position (mm)                       0\nangular position (°)                      0\nmaterial thickness (mm)                   0\nweld number                               0\ncross section positon in the weld (mm)    0\ncracking in the weld metal                0\ndtype: int64"
  },
  {
    "objectID": "exploring-data.html#data-visualization",
    "href": "exploring-data.html#data-visualization",
    "title": "5  Data Wrangling",
    "section": "5.4 Data Visualization",
    "text": "5.4 Data Visualization\nIn order to gain a deeper understanding of the distribution and relationship of each variable, we will explore the dataset visually.\n\n5.4.1 Data Distribution\nVisualizing the distribution of our data will help us understand its central tendency and spread. This can be achieved using histograms.\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfor i in range(len(FEATURES)):\n    plt.subplot(3,2,i+1)\n    sns.histplot(dataset[FEATURES[i]])\n\nplt.tight_layout()\n\n\n\n\nHistogram of the 6-parameters to be studied. Based on above plot, only three levels per parameters were gathered.\n\n\n\n\n\nsns.histplot(dataset[TARGET], discrete=True, stat=\"density\");\n\n\n\n\nHistogram of the target variable. Based on above plot, the target variable was highlighly imbalanced – less than 20% of the dataset has a value of 1.\n\n\n\n\n\n\n5.4.2 Correlation Heatmap\nSome machine learning models assume that input features are not correlated. To check for correlations, we will generate a heatmap of the correlation matrix of our input features. This heatmap will also help us identify which features are correlated with the target variable.\n\ncorr_matrix = dataset[FEATURES].corr()\nsns.heatmap(corr_matrix, annot=True, fmt=\".2f\");\n\n\n\n\nHeatmap of the correlation matrix of the feature variables.\n\n\n\n\nBased on the correlation heatmap, we can observe the following:\n\nThere is no multicollinearity among the input features.\nThe features “power,” “angular position,” and “material thickness” are positively correlated with the presence of cracking in the metal weld.\nThe feature “gas flow rate” is negatively correlated with the presence of cracking in the metal weld."
  },
  {
    "objectID": "exploring-data.html#exporting-the-dataset",
    "href": "exploring-data.html#exporting-the-dataset",
    "title": "5  Data Wrangling",
    "section": "5.5 Exporting the Dataset",
    "text": "5.5 Exporting the Dataset\n\ndataset.to_csv(\"datasets/V1.csv\")"
  },
  {
    "objectID": "exploring-data.html#conclusion",
    "href": "exploring-data.html#conclusion",
    "title": "5  Data Wrangling",
    "section": "5.6 Conclusion",
    "text": "5.6 Conclusion\nIn conclusion, we have explored the dataset and identified the relevant features and target variables for our machine learning model. We have also encoded the binary target variable and visualized the data distribution and correlations. The next steps will involve training and evaluating our machine learning models using this prepared dataset."
  },
  {
    "objectID": "modelling.html#importing-relevant-libraries",
    "href": "modelling.html#importing-relevant-libraries",
    "title": "6  Modelling",
    "section": "6.1 Importing Relevant Libraries",
    "text": "6.1 Importing Relevant Libraries\nThe following code below contains all of the import statements for this section.\n\n# Data Wrangling\nimport numpy as np\nimport pandas as pd\n\n# Data Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Dataset Splitting\nfrom sklearn.model_selection import train_test_split\n\n# Feature Engineering Classes\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n# Machine Learning Model Classes\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import (\n    RandomForestClassifier,\n    VotingClassifier,\n    BaggingClassifier,\n    AdaBoostClassifier,\n    StackingClassifier\n)\n\n# Classification Visualization\nfrom yellowbrick.classifier import ConfusionMatrix, ClassificationReport, ROCAUC\n\n# Base Classes\nfrom sklearn.base import ClassifierMixin, TransformerMixin"
  },
  {
    "objectID": "modelling.html#importing-the-dataset",
    "href": "modelling.html#importing-the-dataset",
    "title": "6  Modelling",
    "section": "6.2 Importing the Dataset",
    "text": "6.2 Importing the Dataset\nThe following code below loads the dataset pre-processed from EDA section into pandas DataFrame.\n\ndataset_uri = \"datasets/V1.csv\"\ndataset = pd.read_csv(dataset_uri, index_col=0)\n\ndataset.head()\n\n\n\n\n\n\n\n\npower (W)\nwelding speed (m/min)\ngas flow rate (l/min)\nfocal position (mm)\nangular position (°)\nmaterial thickness (mm)\nweld number\ncross section positon in the weld (mm)\ncracking in the weld metal\n\n\n\n\n0\n1050\n1.0\n15\n0\n0\n0.6\n1\n8\n0\n\n\n1\n1050\n1.0\n15\n0\n0\n0.6\n1\n16\n0\n\n\n2\n1050\n1.0\n15\n0\n0\n0.6\n1\n24\n0\n\n\n3\n1050\n1.0\n15\n0\n0\n0.6\n1\n32\n0\n\n\n4\n1050\n1.0\n15\n0\n0\n0.6\n2\n8\n0"
  },
  {
    "objectID": "modelling.html#vertical-data-splitting",
    "href": "modelling.html#vertical-data-splitting",
    "title": "6  Modelling",
    "section": "6.3 Vertical Data Splitting",
    "text": "6.3 Vertical Data Splitting\nOnce loaded, the dataset will be splitted into feature matrix X, and target vector y.\n\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values"
  },
  {
    "objectID": "modelling.html#horizontal-data-splitting",
    "href": "modelling.html#horizontal-data-splitting",
    "title": "6  Modelling",
    "section": "6.4 Horizontal Data Splitting",
    "text": "6.4 Horizontal Data Splitting\nOnce the feature matrix and target vector was defined, they will be splitted horizontally into training set and testing set. The code below will perform the horizontal split with test size of 20% with ensuring that both sets contains the same proportion of 0s and 1s on their target variable."
  },
  {
    "objectID": "modelling.html#modelling",
    "href": "modelling.html#modelling",
    "title": "6  Modelling",
    "section": "6.5 Modelling",
    "text": "6.5 Modelling\nTo compare different models, the yellowbrick datavisualization library was used. This library contains out-of-the-box data visualization tools for comparing different machine learning algorithms implemented in scikit-learn. The class definition below provides an abstraction in comparing different machine learning models. Its constructor accepts a list of estimators, an input feature X, and output variable y. It has a show_classification_report method that returns a data visualization of each of the model’s ROC curve, confusion matrix, and classification report.\n\nclass ClassifierEvaluator():\n    def __init__(self, estimators: list[ClassifierMixin], X, y) -&gt; None:\n        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n            X,\n            y,\n            test_size=0.2,\n            stratify=y,\n            random_state=22\n        )\n        self.estimators = estimators\n\n    def show_classification_reports(self) -&gt; None:\n        for estimator in self.estimators:\n            name = type(estimator).__name__\n\n            pipeline = Pipeline(\n                steps=[\n                    (\"std_scaler\", StandardScaler()),\n                    (\"classifier\", estimator)\n                ]\n            )\n\n            pipeline.target_type_ = 'binary'\n\n            # Plot The Report\n            fig, axes = plt.subplots(1,3)\n            fig.set_size_inches(12,6)\n\n            roc = ROCAUC(pipeline, ax=axes[0], binary=True)\n            cm = ConfusionMatrix(pipeline, ax=axes[1], classes=[\"No Crack\", \"Crack\"])\n            cr = ClassificationReport(pipeline, support=True, ax=axes[2], classes=[\"Crack\", \"No Crack\"])\n\n            # Fit the model and the visualizers on the training data\n            roc.fit(self.X_train, self.y_train)\n            cm.fit (self.X_train, self.y_train)\n            cr.fit (self.X_train, self.y_train)\n\n            # Score and show the visualizers on the test data\n            roc.score(self.X_test, self.y_test);\n            cm.score (self.X_test, self.y_test);\n            cr.score (self.X_test, self.y_test);\n\n            fig.suptitle(f\"{type(estimator).__name__}\")\n            axes[0].set_title(f\"{type(roc).__name__}\")\n            axes[1].set_title(f\"{type(cm).__name__}\")\n            axes[2].set_title(f\"{type(cr).__name__}\")\n\n            axes[1].set_xlabel(\"Prediction\")\n            axes[1].set_ylabel(\"Actual\")\n            axes[2].set_xlabel(\"Prediction\")\n            axes[2].set_ylabel(\"Actual\")\n            \n            axes[0].legend();\n\n            plt.tight_layout()\n            plt.show()"
  },
  {
    "objectID": "modelling.html#training-the-model",
    "href": "modelling.html#training-the-model",
    "title": "6  Modelling",
    "section": "6.6 Training the Model",
    "text": "6.6 Training the Model\nThe code below will train the 5 machine learning models using the preprocessed dataset from Data Wrangling section.\n\nevaluator = ClassifierEvaluator(\n    estimators=[\n        LogisticRegression(),\n        DecisionTreeClassifier(),\n        SVC(),\n        GaussianNB(),\n        KNeighborsClassifier()\n    ],\n    X=X,\n    y=y\n)"
  },
  {
    "objectID": "modelling.html#classification-report",
    "href": "modelling.html#classification-report",
    "title": "6  Modelling",
    "section": "6.7 Classification Report",
    "text": "6.7 Classification Report\nThe following series of plots below shows the ROC curve, confusion matrix, and classification report of each models. This visualization can be used to compare the performance of each of the model.\n\nevaluator.show_classification_reports()\n\n\n\n\n\n\nLogistic Regression Model: Precision (95.3%) - Out of 64 samples that the model predicted to have no cracks on welding joints, 3 of them actually have a crack. Recall (70.00%) - Out of all 10 samples with cracks on welding joint, the model was able to correctly predict 7 of them.\n\n\n\n\n\n\n\n\n\nDecision Tree Model: Precision (95.3%) - Out of 64 samples that the model predicted to have no cracks on welding joints, 3 of them actually have a crack. Recall (70.00%) - Out of all 10 samples with cracks on welding joint, the model was able to correctly predict 7 of them. Although its recall, and precsion was same with Logistic regression model, since the area-under-curve of its receiver operating curve was lower thank logistic regression model, it has lesser discriminability.\n\n\n\n\n\n\n\n\n\nSupport Vector Model: Precision (96.8%) - Out of 62 samples that the model predicted to have no cracks on welding joints, 2 of them actually have a crack. Recall (80.00%) - Out of all 10 samples with cracks on welding joint, the model was able to correctly predict 8 of them. At 0.97 AUC, this model’s discriminability is better than the decision tree model.\n\n\n\n\n\n\n\n\n\nGaussian Naive Baye’s: Precision (100.00%) - Out of 47 samples that the model predicted to have no cracks on welding joints, 0 of them actually have a crack. Recall (100.00%) - Out of all 10 samples with cracks on welding joint, the model was able to correctly predict 10 of them.\n\n\n\n\n\n\n\n\n\nK-Nearest-Neighbors Model: Precision (92.2%) - Out of 64 samples that the model predicted to have no cracks on welding joints, 5 of them actually have a crack. Recall (50%) - Out of all 10 samples with cracks on welding joint, the model was able to correctly predict 5 of them. This is the worse model since its ability to correctly predict welding cracks was almost like tossing a fair coin."
  },
  {
    "objectID": "modelling.html#model-evaluation",
    "href": "modelling.html#model-evaluation",
    "title": "6  Modelling",
    "section": "6.8 Model Evaluation",
    "text": "6.8 Model Evaluation\nNow, let’s analyze each of the model according to their recall rate in decreasing order while considering their impact on cost.\n\n6.8.1 GaussianNB Model\nIf a manufacturing business unit does not tolerate any defect out-flow to the next process, a conservative models very high recall rate could be employed such as the GaussianNB model with 100.00% recall-rate (10/10). However keep in mind that this has trade-off – a high false-positive rate of 24.20% (15/62). If the cost of rework due to false detection of welding cracks outweighs the cost of re-inspection and re-processing due to defect outflow, then this model is not feasible.\n\n\n6.8.2 Support Vector Classifier\nIf the business unit allows a compromise (a small rate of defect outflow), while keeping the false-rejection rate at minimum, then the Support Vector Classifier model could be used. Although its recall-rate of 80.00% (8/10) is much smaller than the GaussianNB model, its feasibility can be justified by its low false positive rate of 3.23% (2/62). If the cost of rework due to false detection of welding cracks outweighs the cost of reinspection and reprocessing due to defect outflow, this model is more desirable than GuassianNB.\n\n\n6.8.3 Logistic Regression and Decision Tree\nThese models have low recall rate of 70.00% (7/10), and precision rate of 95.30% (61/64), However, their false positive rate of 1.61% (1/62) were superior against GaussianNB and SVC. Even though these models have superior false positive rate, using them however, bears a significant risk of defect out-flow which might result to poor customer satisfaction.\n\n\n6.8.4 KNN Classifier\nOut of all of the 5-models, this is the worse performing one with inferior recall rate of 50.00% (5/10), inferior precision rate of 92.2% (59/64), and inferior false positive rate of 4.84% (3/62)\n\n\n6.8.5 Conclusion\nBased on the results of the model evaluation, the most feasible model to be used in terms of balance between false positive rate and recall rate was the support vector classifier. Another notable model with good detection of cracks was the Gaussian Naive Baye’s model, however some work should be done to reduce its false positive rate. On the next phase of this project, we will focus our efforts improving the performance of these two models through feature engineering and hyper-parameter tuning. The last three poor classifiers will be revisited in the Ensembling phase to check if they can help in improving the detection of welding cracks."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "7  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Gao, Zhongmei, Yuye Yang, Lei Wang, Bin Zhou, and Fei Yan. 2022.\n“Formation Mechanism and Control of Solidification Cracking in\nLaser-Welded Joints of Steel/Copper Dissimilar Metals.”\nMetals 12 (7): 1147. https://doi.org/10.3390/met12071147.\n\n\nRinne, Jonas. 2021. “Screening Datasets for Laser Welded\nSteel-Copper Lap Joints.” Mendeley Data. https://doi.org/10.17632/2s5m3crbkd.2.\n\n\nRinne, Jonas, Sarah Nothdurft, Jörg Hermsdorf, Stefan Kaierle, and\nLudger Overmeyer. 2021. “Investigations on Laser Welding of\nDissimilar Joints of Stainless Steel and Copper for Hot Crack\nPrevention.” Journal of Laser Applications 33: 042042.\nhttps://doi.org/10.2351/7.0000489."
  }
]